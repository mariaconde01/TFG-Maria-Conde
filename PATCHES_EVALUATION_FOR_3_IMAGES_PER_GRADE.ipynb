{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import binary_fill_holes\n",
        "from skimage.measure import label, regionprops\n",
        "import h5py  # h5py is used for handling HDF5 files\n",
        "import tensorflow as tf  # TensorFlow is a library for machine learning\n",
        "from tensorflow.keras.models import model_from_json  # This imports the function to load Keras models"
      ],
      "metadata": {
        "id": "h5w-6hLI4EMh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the main folder where subfolders will be created\n",
        "main_folder = 'evalmoda'  # Change this path to match your system\n",
        "\n",
        "# Create the main folder if it does not exist\n",
        "if not os.path.exists(main_folder):\n",
        "    os.makedirs(main_folder)\n",
        "\n",
        "# Define the subfolders for each grade (Gr_0, Gr_1, Gr_2, Gr_3)\n",
        "subfolders = ['Gr_0', 'Gr_1', 'Gr_2', 'Gr_3']\n",
        "\n",
        "# Create the subfolders inside the main folder\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(main_folder, subfolder)\n",
        "    if not os.path.exists(subfolder_path):\n",
        "        os.makedirs(subfolder_path)\n",
        "\n",
        "# Define the path to the folder that contains the images\n",
        "image_folder = '/content/drive/MyDrive/imagenes moda'  # Change this path to where your images are stored\n",
        "\n",
        "# List all the images in the image folder\n",
        "images = os.listdir(image_folder)\n",
        "\n",
        "# Move the images to the corresponding subfolders based on the grade in the file name\n",
        "for image_name in images:\n",
        "    image_path = os.path.join(image_folder, image_name)\n",
        "\n",
        "    # Check the grade in the file name and assign it to the correct subfolder\n",
        "    if 'Gr0' in image_name:\n",
        "        grado = 'Gr_0'\n",
        "    elif 'Gr1' in image_name:\n",
        "        grado = 'Gr_1'\n",
        "    elif 'Gr2' in image_name:\n",
        "        grado = 'Gr_2'\n",
        "    elif 'Gr3' in image_name:\n",
        "        grado = 'Gr_3'\n",
        "    else:\n",
        "        # If the grade is not found in the filename, print a message and continue\n",
        "        print(f'Grade not identified in the file name: {image_name}')\n",
        "        continue\n",
        "\n",
        "    # Define the destination folder path\n",
        "    destination_folder = os.path.join(main_folder, grado)\n",
        "\n",
        "    # Move the image to the corresponding subfolder\n",
        "    shutil.move(image_path, destination_folder)\n",
        "\n",
        "    # Print a message indicating the image has been moved\n",
        "    print(f'Moved {image_path} to {destination_folder}')\n"
      ],
      "metadata": {
        "id": "7SetnnDOBBpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input and output folder paths\n",
        "input_folder = '/content/evalmoda'\n",
        "output_folder = '/content/modapreprocess_final'\n",
        "preprocessed_folder = os.path.join(output_folder, 'preprocessed')\n",
        "\n",
        "# Function to determine the grade of an image based on its filename\n",
        "def determine_grade(filename):\n",
        "    if \"Gr0\" in filename:\n",
        "        return 0\n",
        "    elif \"Gr1\" in filename:\n",
        "        return 1\n",
        "    elif \"Gr2\" in filename:\n",
        "        return 2\n",
        "    elif \"Gr3\" in filename:\n",
        "        return 3\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Function to process an individual image\n",
        "def process_image(input_path, output_path, filename):\n",
        "    input_file_path = os.path.join(input_path, filename)\n",
        "    output_file_path = os.path.join(output_path, filename)\n",
        "\n",
        "    try:\n",
        "        color_image = cv2.imread(input_file_path)\n",
        "        cropped_image = color_image[:3072, :]\n",
        "        gray_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        black_pixels = (gray_image == 0)\n",
        "        black_pixels_mask = np.zeros_like(gray_image)\n",
        "        black_pixels_mask[black_pixels] = 255\n",
        "\n",
        "        kernel = np.ones((300, 300), np.uint8)\n",
        "        dilated_mask = cv2.dilate(black_pixels_mask, kernel, iterations=1)\n",
        "\n",
        "        adjacent_white_pixels = (cv2.dilate(dilated_mask, np.ones((9, 9), np.uint8), iterations=1) - dilated_mask) > 0\n",
        "        whitish_tone = np.mean(gray_image[adjacent_white_pixels])\n",
        "\n",
        "        if not np.isfinite(whitish_tone):\n",
        "            whitish_tone = 220\n",
        "\n",
        "        gray_image[dilated_mask > 0] = whitish_tone\n",
        "\n",
        "        _, otsu_threshold = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        # Invert the Otsu threshold image to focus on the black regions\n",
        "        inverted_otsu_threshold = cv2.bitwise_not(otsu_threshold)\n",
        "\n",
        "        # Fill holes using scipy.ndimage.binary_fill_holes\n",
        "        filled_image = binary_fill_holes(inverted_otsu_threshold).astype(np.uint8) * 255\n",
        "\n",
        "        # Label the binary image\n",
        "        labeled_image, num_features = label(filled_image, return_num=True, connectivity=2)\n",
        "\n",
        "        # Get properties of the labeled regions\n",
        "        regions = regionprops(labeled_image)\n",
        "\n",
        "        # Find the largest region based on area\n",
        "        if regions:\n",
        "            largest_region = max(regions, key=lambda r: r.area)\n",
        "            largest_region_mask = (labeled_image == largest_region.label).astype(np.uint8) * 255\n",
        "        else:\n",
        "            largest_region_mask = filled_image\n",
        "\n",
        "        final_color_image = cv2.bitwise_and(cropped_image, cropped_image, mask=largest_region_mask)\n",
        "\n",
        "        plt.figure(figsize=(18, 6))\n",
        "        plt.subplot(1, 4, 1)\n",
        "        plt.imshow(cv2.cvtColor(otsu_threshold, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.title(\"otsu_threshold\")\n",
        "\n",
        "        plt.subplot(1, 4, 2)\n",
        "        plt.imshow(filled_image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.title(\"Filled Holes\")\n",
        "\n",
        "        plt.subplot(1, 4, 3)\n",
        "        plt.imshow(largest_region_mask, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.title(\"Largest Region Mask\")\n",
        "\n",
        "        plt.subplot(1, 4, 4)\n",
        "        plt.imshow(cv2.cvtColor(final_color_image, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.title(\"Final Color Image\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        grade = determine_grade(filename)\n",
        "        if grade is not None:\n",
        "            grade_folder = os.path.join(preprocessed_folder, f'grade{grade}')\n",
        "            os.makedirs(grade_folder, exist_ok=True)\n",
        "            output_filename = f\"processed_{filename}\"\n",
        "            preprocessed_output_path = os.path.join(grade_folder, output_filename)\n",
        "            cv2.imwrite(preprocessed_output_path, final_color_image)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process the image: {input_file_path}\")\n",
        "        print(f\"Error: {str(e)}\")\n",
        "\n",
        "if os.path.exists(output_folder):\n",
        "    shutil.rmtree(output_folder)\n",
        "os.makedirs(output_folder)\n",
        "os.makedirs(preprocessed_folder)\n",
        "\n",
        "for root, folders, files in os.walk(input_folder):\n",
        "    for filename in files:\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.tif', '.tiff')):\n",
        "            process_image(root, output_folder, filename)\n",
        "\n",
        "print('Process completed.')\n"
      ],
      "metadata": {
        "id": "pHCk1YlXB9uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input and output folder paths for image patches\n",
        "preprocessed_folder = '/content/modapreprocess_final/preprocessed'  # Folder containing the preprocessed images\n",
        "patches_folder = '/content/emodapatches'  # Main folder for patches\n",
        "patches_output_folder = os.path.join(patches_folder, 'patches')  # Folder where the patches will be saved\n",
        "\n",
        "# Create the output folder for image patches if it doesn't exist\n",
        "os.makedirs(patches_output_folder, exist_ok=True)\n",
        "\n",
        "# Create subfolders for each grade inside the patches folder\n",
        "for grade in range(4):\n",
        "    # Creating subfolders (grade0, grade1, grade2, grade3) to organize patches by grade\n",
        "    os.makedirs(os.path.join(patches_output_folder, f'grade{grade}'), exist_ok=True)\n",
        "\n",
        "# Function to create patches from an image\n",
        "def create_patches(image_path, output_folder, patch_size=(3072, 3072), stride=512):\n",
        "    \"\"\"\n",
        "    Splits an image into smaller patches.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "        output_folder (str): Folder where the patches will be saved.\n",
        "        patch_size (tuple): The size of each patch (height, width).\n",
        "        stride (int): The step size for sliding the window over the image.\n",
        "\n",
        "    Returns:\n",
        "        None: Patches are saved directly to the output folder.\n",
        "    \"\"\"\n",
        "    # Read the image from the path\n",
        "    image = cv2.imread(image_path)\n",
        "    image_height, image_width, _ = image.shape  # Get image dimensions\n",
        "    patch_count = 0  # Initialize the counter for patches\n",
        "\n",
        "    # Loop through the image to create patches\n",
        "    for y in range(0, image_height, stride):\n",
        "        for x in range(0, image_width, stride):\n",
        "            # Ensure the patch fits within the image boundaries\n",
        "            if y + patch_size[1] <= image_height and x + patch_size[0] <= image_width:\n",
        "                # Extract the patch from the image\n",
        "                patch = image[y:y + patch_size[1], x:x + patch_size[0]]\n",
        "                patch_filename = f'{os.path.splitext(os.path.basename(image_path))[0]}_patch_{patch_count}.png'\n",
        "                patch_output_path = os.path.join(output_folder, patch_filename)\n",
        "                # Save the patch to the output folder\n",
        "                cv2.imwrite(patch_output_path, patch)\n",
        "                patch_count += 1  # Increment the patch counter\n",
        "\n",
        "# Loop through all images in the preprocessed folder for each grade and create patches\n",
        "for grade in range(4):\n",
        "    grade_folder = os.path.join(preprocessed_folder, f'grade{grade}')  # Get the folder for the current grade\n",
        "    patches_grade_folder = os.path.join(patches_output_folder, f'grade{grade}')  # Corresponding patch folder for the grade\n",
        "    for filename in os.listdir(grade_folder):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.tif', '.tiff', '.png')):  # Filter image files\n",
        "            img_path = os.path.join(grade_folder, filename)\n",
        "            create_patches(img_path, patches_grade_folder)  # Create patches for the image\n",
        "\n",
        "# Print a confirmation message once all images have been patched\n",
        "print('All images have been patched.')\n",
        "\n"
      ],
      "metadata": {
        "id": "pKIVADCuB95B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder containing the image patches\n",
        "patches_folder = '/content/emodapatches/patches'  # Folder where all patches are stored\n",
        "\n",
        "# Define the minimum tissue percentage required to keep a patch (30% of the patch must contain tissue)\n",
        "min_tissue_percentage = 0.30  # 30% of the patch should contain tissue (non-black pixels)\n",
        "\n",
        "# Function to calculate the percentage of tissue in a patch\n",
        "def calculate_tissue_percentage(patch):\n",
        "    \"\"\"\n",
        "    This function calculates the percentage of tissue (non-black pixels) in an image patch.\n",
        "\n",
        "    Args:\n",
        "        patch (numpy array): The input image patch to be analyzed.\n",
        "\n",
        "    Returns:\n",
        "        float: The percentage of tissue (non-black pixels) in the patch.\n",
        "    \"\"\"\n",
        "    # Convert the patch to grayscale for easier processing\n",
        "    gray_patch = cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply a binary threshold to detect tissue (non-black pixels)\n",
        "    _, thresholded_patch = cv2.threshold(gray_patch, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Count the number of tissue (non-black) pixels\n",
        "    tissue_pixels = np.sum(thresholded_patch == 255)\n",
        "\n",
        "    # Calculate the total number of pixels in the patch\n",
        "    total_pixels = thresholded_patch.size\n",
        "\n",
        "    # Compute the tissue percentage\n",
        "    tissue_percentage = tissue_pixels / total_pixels\n",
        "\n",
        "    return tissue_percentage\n",
        "\n",
        "# Function to remove patches with insufficient tissue (less than the specified threshold)\n",
        "def remove_patches_with_little_tissue(patch_folder):\n",
        "    \"\"\"\n",
        "    This function removes patches from a folder if their tissue percentage is below the defined threshold.\n",
        "\n",
        "    Args:\n",
        "        patch_folder (str): The folder containing the patches (organized by grades).\n",
        "    \"\"\"\n",
        "    # Loop through each grade folder (grade0, grade1, grade2, grade3)\n",
        "    for grade in range(4):  # Iterate through each grade folder (grade0, grade1, grade2, grade3)\n",
        "        grade_folder = os.path.join(patch_folder, f'grade{grade}')  # Get the path for the current grade folder\n",
        "\n",
        "        # Iterate over all files in the grade folder\n",
        "        for filename in os.listdir(grade_folder):\n",
        "            if filename.endswith(('.jpg', '.jpeg', '.tif', '.tiff', '.png')):  # Process image files only\n",
        "                patch_path = os.path.join(grade_folder, filename)  # Full path to the patch\n",
        "\n",
        "                # Read the patch image\n",
        "                patch = cv2.imread(patch_path)\n",
        "\n",
        "                # Calculate the tissue percentage in the patch\n",
        "                tissue_percentage = calculate_tissue_percentage(patch)\n",
        "\n",
        "                # If the tissue percentage is below the defined threshold, remove the patch\n",
        "                if tissue_percentage < min_tissue_percentage:\n",
        "                    os.remove(patch_path)  # Delete the patch\n",
        "                    print(f'Removed patch: {patch_path} (tissue percentage: {tissue_percentage:.2f})')\n",
        "\n",
        "# Call the function to remove patches with insufficient tissue from the entire dataset\n",
        "remove_patches_with_little_tissue(patches_folder)\n",
        "\n",
        "# Print a confirmation message once the process is complete\n",
        "print('Patches with insufficient tissue have been removed.')\n"
      ],
      "metadata": {
        "id": "yuwROq0SB9-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder where all previously generated image patches are located\n",
        "patches_folder = '/content/emodapatches/patches'  # Folder containing the patches\n",
        "\n",
        "# Define the output folder where the resized patches will be saved\n",
        "resized_folder = '/content/resizedmoda'  # Output folder for resized patches\n",
        "\n",
        "# Define the target output size (512x512 pixels)\n",
        "output_size = (512, 512)\n",
        "\n",
        "# Create the output folder if it doesn't already exist\n",
        "os.makedirs(resized_folder, exist_ok=True)\n",
        "\n",
        "# Function to resize an image\n",
        "def resize_image(image, size=(512, 512)):\n",
        "    \"\"\"\n",
        "    Resizes the input image to the specified size using INTER_AREA resampling method.\n",
        "\n",
        "    Args:\n",
        "        image (numpy array): The image to be resized.\n",
        "        size (tuple): The target size to resize the image to.\n",
        "\n",
        "    Returns:\n",
        "        numpy array: The resized image.\n",
        "    \"\"\"\n",
        "    # Using INTER_AREA interpolation for resampling (better for downsampling)\n",
        "    resized_image = cv2.resize(image, size, interpolation=cv2.INTER_AREA)\n",
        "    return resized_image\n",
        "\n",
        "# Function to resize all patches in a given folder\n",
        "def resize_patches_in_folder(patch_folder, resized_folder):\n",
        "    \"\"\"\n",
        "    Resizes all image patches in the specified folder and saves them to the resized folder.\n",
        "    The patches are resized to the target size (512x512 pixels).\n",
        "\n",
        "    Args:\n",
        "        patch_folder (str): The folder containing the original image patches.\n",
        "        resized_folder (str): The folder where the resized patches will be stored.\n",
        "    \"\"\"\n",
        "    # Iterate through each grade folder (0, 1, 2, 3)\n",
        "    for grade in range(4):  # Loop over the grade folders (grade0, grade1, grade2, grade3)\n",
        "        grade_folder = os.path.join(patch_folder, f'grade{grade}')  # Path to the current grade folder\n",
        "        resized_grade_folder = os.path.join(resized_folder, f'grade{grade}')  # Path to the resized grade folder\n",
        "\n",
        "        # Create the resized grade folder if it doesn't exist\n",
        "        os.makedirs(resized_grade_folder, exist_ok=True)\n",
        "\n",
        "        # Loop through all image patches in the current grade folder\n",
        "        for filename in os.listdir(grade_folder):\n",
        "            if filename.endswith(('.jpg', '.jpeg', '.tif', '.tiff', '.png')):  # Process only image files\n",
        "                patch_path = os.path.join(grade_folder, filename)  # Full path to the current patch\n",
        "\n",
        "                # Read the patch image\n",
        "                patch = cv2.imread(patch_path)\n",
        "\n",
        "                if patch is not None:\n",
        "                    # Resize the image (resample it to the target size)\n",
        "                    resized_patch = resize_image(patch, output_size)\n",
        "\n",
        "                    # Save the resized image in the resized folder\n",
        "                    resized_patch_path = os.path.join(resized_grade_folder, f'resized_{filename}')\n",
        "                    cv2.imwrite(resized_patch_path, resized_patch)  # Save the resized image\n",
        "                    print(f'Resized and saved: {resized_patch_path}')  # Print the path of the resized image\n",
        "                else:\n",
        "                    print(f'Error reading image: {patch_path}')  # Handle error if the patch cannot be read\n",
        "\n",
        "# Resize all patches in the train and test folders\n",
        "resize_patches_in_folder(patches_folder, resized_folder)\n",
        "\n",
        "# Print a confirmation message once the process is complete\n",
        "print('All images have been resampled to 512x512 and saved to the resized folders.')\n",
        "\n"
      ],
      "metadata": {
        "id": "uZyCXUqFB-GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Keras model from an H5 file\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Ph5 y json/E15model_sin_finetunningdensenet121.h5')"
      ],
      "metadata": {
        "id": "xt0ftqviu-Qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the ImageDataGenerator class from Keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Importing tools from scikit-learn for evaluating the model\n",
        "from sklearn.metrics import classification_report, confusion_matrix  # Used for generating performance metrics (report and confusion matrix)\n",
        "\n",
        "# Create an instance of ImageDataGenerator for image rescaling (normalization)\n",
        "datagen = ImageDataGenerator(rescale=1./255)  # Rescales image pixel values to the range [0, 1]\n",
        "\n",
        "# Create a generator that will load images from the specified directory\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    '/content/resizedmoda',  # Path to the test dataset\n",
        "    target_size=(512, 512),  # Resizes all images to the target size (512x512 pixels)\n",
        "    batch_size=32,  # Number of images to process in each batch\n",
        "    class_mode='categorical',  # Specifies the format of the labels (for multi-class classification)\n",
        "    shuffle=False  # Don't shuffle the data, as this is for evaluation on the test set\n",
        ")"
      ],
      "metadata": {
        "id": "Ql74QEb-locq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fNKmkMujubL"
      },
      "outputs": [],
      "source": [
        "image_names = []\n",
        "# Obtain predictions in small batches to avoid memory issues\n",
        "y_pred = []  # List to store predicted labels\n",
        "y_true = []  # List to store true labels\n",
        "\n",
        "# Loop through the test set and make predictions in batches\n",
        "for i in range(len(test_generator)):\n",
        "    X, y = test_generator[i]  # Get a batch of data (images and labels)\n",
        "    y_pred.extend(np.argmax(model.predict(X), axis=1))  # Predict the class with the highest probability\n",
        "    y_true.extend(np.argmax(y, axis=1))  # Get the true labels (index of the highest value)\n",
        "    batch_image_names = test_generator.filenames[i * test_generator.batch_size : (i + 1) * test_generator.batch_size]\n",
        "    image_names.extend(batch_image_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will give you a list of which classes each patch belongs to (in theory all patches should belong to the same class)."
      ],
      "metadata": {
        "id": "QczJilhGtAe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict  # Import defaultdict to keep track of counts and lists for each image\n",
        "\n",
        "# `image_patch_count` will store the number of patches for each image\n",
        "# `image_predictions` will store the predictions for each image, indexed by the image name\n",
        "image_patch_count = defaultdict(int)  # Initialize the dictionary to count patches per image (default value is 0)\n",
        "image_predictions = defaultdict(list)  # Initialize the dictionary to store predictions per image (default value is an empty list)\n",
        "\n",
        "# Initialize an index variable to iterate through the patch names and corresponding predictions\n",
        "index = 0\n",
        "\n",
        "# Loop over each patch name in `image_names`\n",
        "for patch_name in image_names:\n",
        "    # Extract the image name by removing the last part (patch number) from the patch name\n",
        "    # Assumes the patch name format is \"imageName_patchNumber\", so we split by \"_\" and join everything except the last part\n",
        "    image_name = \"_\".join(patch_name.split(\"_\")[:-1])\n",
        "\n",
        "    # Increment the patch count for the current image\n",
        "    image_patch_count[image_name] += 1\n",
        "\n",
        "    # Append the prediction for the current patch to the list of predictions for this image\n",
        "    image_predictions[image_name].append(y_pred[index])\n",
        "\n",
        "    # Move to the next prediction (increment the index)\n",
        "    index += 1\n"
      ],
      "metadata": {
        "id": "VSrQyHWrviRZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_name, preds in image_predictions.items():\n",
        "    print(f'Image: {image_name}')\n",
        "    print(f'Predictions: {preds}')"
      ],
      "metadata": {
        "id": "zeiNwDFB1LsU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2c6a93fe-7604-439f-daf5-1d6afc0363bc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: grade0/resized_processed_Gr0_SafO_018_patch\n",
            "Predictions: [0, 0, 0, 0, 0, 0]\n",
            "Image: grade0/resized_processed_Gr0_SafO_026_patch\n",
            "Predictions: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Image: grade0/resized_processed_Gr0_SafO_043_patch\n",
            "Predictions: [0, 0, 0, 0, 0, 0, 0]\n",
            "Image: grade1/resized_processed_Gr1_Saf_053_patch\n",
            "Predictions: [0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
            "Image: grade1/resized_processed_Gr1_Saf_057_patch\n",
            "Predictions: [2, 2]\n",
            "Image: grade1/resized_processed_Gr1_Saf_120_patch\n",
            "Predictions: [2, 2, 1, 1, 1]\n",
            "Image: grade2/resized_processed_Gr2_Saf_001_patch\n",
            "Predictions: [2, 2, 2, 2, 2, 2, 2]\n",
            "Image: grade2/resized_processed_Gr2_Saf_032_patch\n",
            "Predictions: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "Image: grade2/resized_processed_Gr2_Saf_038_patch\n",
            "Predictions: [2, 2, 2, 2, 2, 2]\n",
            "Image: grade3/resized_processed_Gr3_Saf_058_patch\n",
            "Predictions: [3, 3, 3, 3, 3]\n",
            "Image: grade3/resized_processed_Gr3_Saf_069_patch\n",
            "Predictions: [3, 3, 3, 3, 3]\n",
            "Image: grade3/resized_processed_Gr3_Saf_088_patch\n",
            "Predictions: [3, 3, 3, 3, 3, 3]\n"
          ]
        }
      ]
    }
  ]
}