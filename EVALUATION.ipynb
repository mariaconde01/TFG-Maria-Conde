{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import h5py  # h5py is used for handling HDF5 files\n",
        "import tensorflow as tf  # TensorFlow is a library for machine learning\n",
        "from tensorflow.keras.models import model_from_json  # This imports the function to load Keras models"
      ],
      "metadata": {
        "id": "Hf9_Cx9zWPGH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Keras model from an H5 file\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Ph5 y json/E15model_sin_finetunningrEfficientnetv2b0.h5')"
      ],
      "metadata": {
        "id": "fEjGQbIzWPJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the summary of the model's architecture\n",
        "model.summary()  # This shows the structure and layers of the model"
      ],
      "metadata": {
        "id": "e7gSuZheWPLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the ImageDataGenerator class from Keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Importing tools from scikit-learn for evaluating the model\n",
        "from sklearn.metrics import classification_report, confusion_matrix  # Used for generating performance metrics (report and confusion matrix)\n"
      ],
      "metadata": {
        "id": "Dbj-wNF8Zuoa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of ImageDataGenerator for image rescaling (normalization)\n",
        "datagen = ImageDataGenerator(rescale=1./255)  # Rescales image pixel values to the range [0, 1]\n",
        "\n",
        "# Create a generator that will load images from the specified directory\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    '/content/DATASET evauaciOn/resizedtestpatches',  # Path to the test dataset\n",
        "    target_size=(512, 512),  # Resizes all images to the target size (512X512 pixels)\n",
        "    batch_size=32,  # Number of images to process in each batch\n",
        "    class_mode='categorical',  # Specifies the format of the labels (for multi-class classification)\n",
        "    shuffle=False  # Don't shuffle the data, as this is for evaluation on the test set\n",
        ")"
      ],
      "metadata": {
        "id": "Gt0DqhZpWPP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear the Keras session to free up memory\n",
        "tf.keras.backend.clear_session()  # This is used to reset the Keras backend, clearing the session and freeing memory\n"
      ],
      "metadata": {
        "id": "CgKz-u0xWPSB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with the specified optimizer, loss function, and evaluation metrics\n",
        "model.compile(optimizer='adam',  # Adam optimizer is used for efficient gradient descent\n",
        "              loss='categorical_crossentropy',  # Loss function for multi-class classification problems\n",
        "              metrics=['accuracy'])  # Metric to track during training and evaluation\n"
      ],
      "metadata": {
        "id": "5BEQCw3LWPUp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Evaluate the model on the test data and get the results for each metric\n",
        "results = model.evaluate(test_generator)  # Evaluates the model on the test set and returns the loss and metrics\n",
        "\n",
        "# Print the result for each metric (e.g., accuracy, loss)\n",
        "for metric_name, value in zip(model.metrics_names, results):\n",
        "    print(f'{metric_name}: {value}')  # Prints the name of each metric and its corresponding value\n",
        "\n",
        "# Obtain predictions in small batches to avoid memory issues\n",
        "y_pred = []  # List to store predicted labels\n",
        "y_true = []  # List to store true labels\n",
        "\n",
        "# Loop through the test set and make predictions in batches\n",
        "for i in range(len(test_generator)):\n",
        "    X, y = test_generator[i]  # Get a batch of data (images and labels)\n",
        "    y_pred.extend(np.argmax(model.predict(X), axis=1))  # Predict the class with the highest probability\n",
        "    y_true.extend(np.argmax(y, axis=1))  # Get the true labels (index of the highest value)\n",
        "\n",
        "# Print classification report (precision, recall, f1-score)\n",
        "print(classification_report(y_true, y_pred, target_names=list(test_generator.class_indices.keys())))\n",
        "\n",
        "# Print confusion matrix to evaluate the performance of the model\n",
        "print(confusion_matrix(y_true, y_pred))  # Confusion matrix shows the number of correct/incorrect predictions"
      ],
      "metadata": {
        "id": "H3oy9MLSWPW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Seaborn library for data visualization (for plotting)\n",
        "import seaborn as sns  # Seaborn is used for creating statistical graphics in Python\n",
        "\n",
        "# Importing Matplotlib for additional plotting functionalities\n",
        "import matplotlib.pyplot as plt  # Matplotlib is used for generating visualizations like graphs and charts\n"
      ],
      "metadata": {
        "id": "rz0QF7cHWPZR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of the confusion matrix to see its dimensions\n",
        "confusion_matrix_shape = confusion_matrix(y_true, y_pred).shape  # Returns the dimensions (shape) of the confusion matrix\n"
      ],
      "metadata": {
        "id": "NOd0VWWfWPbe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))  # Adjust the figure size if needed\n",
        "sns.heatmap(confusion_matrix(y_true, y_pred),  # Plot the confusion matrix\n",
        "            annot=True,  # Annotates each cell with its numeric value\n",
        "            fmt='d',  # Format the annotation as an integer\n",
        "            cmap='Blues',  # Use a blue color map for the heatmap\n",
        "            xticklabels=test_generator.class_indices.keys(),  # Set x-axis labels to class names\n",
        "            yticklabels=test_generator.class_indices.keys())  # Set y-axis labels to class names\n",
        "\n",
        "plt.xlabel('Prediction')  # Label for the x-axis (Predicted classes)\n",
        "plt.ylabel('True values')  # Label for the y-axis (True classes)\n",
        "plt.title('Confusion Matrix')  # Title of the plot\n",
        "plt.show()  # Display the plot"
      ],
      "metadata": {
        "id": "bNtjSwMKWPd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json  # Importing the JSON library for parsing JSON files\n",
        "import matplotlib.pyplot as plt  # Importing Matplotlib for plotting graphs\n",
        "import numpy as np  # Importing NumPy for numerical operations\n",
        "\n",
        "# List of paths to JSON files (one per fold in cross-validation)\n",
        "json_files = [\n",
        "    '/content/drive/MyDrive/Ph5 y json/E15history_sin_finetunningrEfficientnetv2b0.json',  # Path to the JSON file containing history data\n",
        "]\n",
        "\n",
        "# Initializing lists to store metrics from each fold\n",
        "accuracy_train = []  # List to store training accuracy\n",
        "accuracy_val = []  # List to store validation accuracy\n",
        "loss_train = []  # List to store training loss\n",
        "loss_val = []  # List to store validation loss\n",
        "\n",
        "# Load and process each JSON file\n",
        "for file in json_files:\n",
        "    with open(file, 'r') as f:  # Open the JSON file in read mode\n",
        "        history = json.load(f)  # Load the JSON content into a dictionary\n",
        "\n",
        "        # Extend the lists with the data from the JSON\n",
        "        accuracy_train.extend(history['accuracy'])  # Training accuracy\n",
        "        accuracy_val.extend(history['val_accuracy'])  # Validation accuracy\n",
        "        loss_train.extend(history['loss'])  # Training loss\n",
        "        loss_val.extend(history['val_loss'])  # Validation loss\n",
        "\n",
        "# Convert metrics to NumPy arrays for easier analysis\n",
        "accuracy_train = np.array(accuracy_train)\n",
        "accuracy_val = np.array(accuracy_val)\n",
        "loss_train = np.array(loss_train)\n",
        "loss_val = np.array(loss_val)\n",
        "\n",
        "# Plot the metrics for each epoch\n",
        "epochs = np.arange(1, accuracy_train.shape[0] + 1)  # Create an array of epoch numbers\n",
        "\n",
        "plt.figure(figsize=(12, 6))  # Set the size of the figure\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, accuracy_train, label='Train Accuracy', color='blue')  # Training accuracy curve\n",
        "plt.plot(epochs, accuracy_val, label='Validation Accuracy', color='green', linestyle='--')  # Validation accuracy curve\n",
        "plt.title('Accuracy per Epoch')  # Title for the accuracy plot\n",
        "plt.xlabel('Epoch')  # X-axis label for epochs\n",
        "plt.ylabel('Accuracy')  # Y-axis label for accuracy\n",
        "plt.legend()  # Show the legend\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss_train, label='Train Loss', color='red')  # Training loss curve\n",
        "plt.plot(epochs, loss_val, label='Validation Loss', color='orange', linestyle='--')  # Validation loss curve\n",
        "plt.title('Loss per Epoch')  # Title for the loss plot\n",
        "plt.xlabel('Epoch')  # X-axis label for epochs\n",
        "plt.ylabel('Loss')  # Y-axis label for loss\n",
        "plt.legend()  # Show the legend\n",
        "\n",
        "plt.tight_layout()  # Adjust the layout for better spacing\n",
        "plt.show()  # Display the plots\n",
        "\n",
        "# Global accuracy statistics (mean and standard deviation)\n",
        "mean_accuracy_train = np.mean(accuracy_train)  # Mean training accuracy\n",
        "std_accuracy_train = np.std(accuracy_train)  # Standard deviation of training accuracy\n",
        "mean_accuracy_val = np.mean(accuracy_val)  # Mean validation accuracy\n",
        "std_accuracy_val = np.std(accuracy_val)  # Standard deviation of validation accuracy\n",
        "\n",
        "# Print the global accuracy statistics\n",
        "print(f\"Mean training accuracy: {mean_accuracy_train:.4f} ± {std_accuracy_train:.4f}\")\n",
        "print(f\"Mean validation accuracy: {mean_accuracy_val:.4f} ± {std_accuracy_val:.4f}\")\n",
        "\n",
        "# Global loss statistics (mean and standard deviation)\n",
        "mean_loss_train = np.mean(loss_train)  # Mean training loss\n",
        "std_loss_train = np.std(loss_train)  # Standard deviation of training loss\n",
        "mean_loss_val = np.mean(loss_val)  # Mean validation loss\n",
        "std_loss_val = np.std(loss_val)  # Standard deviation of validation loss\n",
        "\n",
        "# Print the global loss statistics\n",
        "print(f\"Mean training loss: {mean_loss_train:.4f} ± {std_loss_train:.4f}\")\n",
        "print(f\"Mean validation loss: {mean_loss_val:.4f} ± {std_loss_val:.4f}\")\n"
      ],
      "metadata": {
        "id": "0OtaTMGaWPhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc"
      ],
      "metadata": {
        "id": "Mmcgd7BIWPjf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(test_generator)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "y_true = test_generator.classes"
      ],
      "metadata": {
        "id": "HIpfoJNhWPlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Binarize the labels for multi-class ROC calculation\n",
        "y_true_bin = label_binarize(y_true, classes=list(range(len(test_generator.class_indices))))\n",
        "n_classes = y_true_bin.shape[1]\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], Y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), Y_pred.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
      ],
      "metadata": {
        "id": "qR6XRDZJWPoB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC PLOT\n",
        "plt.figure()\n",
        "colors = ['aqua', 'darkorange', 'cornflowerblue', 'red', 'green', 'purple', 'brown', 'pink', 'gray', 'olive'] # Add more colors if needed\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                   ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) for each class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pjmqFtXmWPqK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}